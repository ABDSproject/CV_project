{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d92dc5e8",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Keras-Tuner-for-Age-and-Gender-Prediction\" data-toc-modified-id=\"Keras-Tuner-for-Age-and-Gender-Prediction-1\">Keras Tuner for Age and Gender Prediction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1.1\">Imports</a></span></li><li><span><a href=\"#Загрузка-данных\" data-toc-modified-id=\"Загрузка-данных-1.2\">Загрузка данных</a></span></li><li><span><a href=\"#Keras-model-creation\" data-toc-modified-id=\"Keras-model-creation-1.3\">Keras model creation</a></span><ul class=\"toc-item\"><li><span><a href=\"#age-model-for-keras-tuner\" data-toc-modified-id=\"age-model-for-keras-tuner-1.3.1\">age model for keras tuner</a></span></li><li><span><a href=\"#AGE-ImageDataGenerator\" data-toc-modified-id=\"AGE-ImageDataGenerator-1.3.2\">AGE ImageDataGenerator</a></span></li><li><span><a href=\"#Создаем-tuner\" data-toc-modified-id=\"Создаем-tuner-1.3.3\">Создаем tuner</a></span></li><li><span><a href=\"#Запускаем-подбор-гиперпараметров\" data-toc-modified-id=\"Запускаем-подбор-гиперпараметров-1.3.4\">Запускаем подбор гиперпараметров</a></span><ul class=\"toc-item\"><li><span><a href=\"#Пространство-поиска\" data-toc-modified-id=\"Пространство-поиска-1.3.4.1\">Пространство поиска</a></span></li><li><span><a href=\"#Подбор-гиперпараметров\" data-toc-modified-id=\"Подбор-гиперпараметров-1.3.4.2\">Подбор гиперпараметров</a></span></li><li><span><a href=\"#Выбираем-лучшую-модель\" data-toc-modified-id=\"Выбираем-лучшую-модель-1.3.4.3\">Выбираем лучшую модель</a></span></li><li><span><a href=\"#Получаем-три-лучших-модели\" data-toc-modified-id=\"Получаем-три-лучших-модели-1.3.4.4\">Получаем три лучших модели</a></span></li><li><span><a href=\"#Оцениваем-качество-модели-на-тестовых-данных\" data-toc-modified-id=\"Оцениваем-качество-модели-на-тестовых-данных-1.3.4.5\">Оцениваем качество модели на тестовых данных</a></span></li></ul></li><li><span><a href=\"#gen-model-for-keras-tuner\" data-toc-modified-id=\"gen-model-for-keras-tuner-1.3.5\">gen model for keras tuner</a></span></li><li><span><a href=\"#GENDER-ImageDataGenerator\" data-toc-modified-id=\"GENDER-ImageDataGenerator-1.3.6\">GENDER ImageDataGenerator</a></span></li><li><span><a href=\"#Создаем-tuner\" data-toc-modified-id=\"Создаем-tuner-1.3.7\">Создаем tuner</a></span></li><li><span><a href=\"#Запускаем-подбор-гиперпараметров\" data-toc-modified-id=\"Запускаем-подбор-гиперпараметров-1.3.8\">Запускаем подбор гиперпараметров</a></span><ul class=\"toc-item\"><li><span><a href=\"#Пространство-поиска\" data-toc-modified-id=\"Пространство-поиска-1.3.8.1\">Пространство поиска</a></span></li><li><span><a href=\"#Подбор-гиперпараметров\" data-toc-modified-id=\"Подбор-гиперпараметров-1.3.8.2\">Подбор гиперпараметров</a></span></li><li><span><a href=\"#Выбираем-лучшую-модель\" data-toc-modified-id=\"Выбираем-лучшую-модель-1.3.8.3\">Выбираем лучшую модель</a></span></li><li><span><a href=\"#Получаем-три-лучших-модели\" data-toc-modified-id=\"Получаем-три-лучших-модели-1.3.8.4\">Получаем три лучших модели</a></span></li><li><span><a href=\"#Оцениваем-качество-модели-на-тестовых-данных\" data-toc-modified-id=\"Оцениваем-качество-модели-на-тестовых-данных-1.3.8.5\">Оцениваем качество модели на тестовых данных</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119637df",
   "metadata": {},
   "source": [
    "# Keras Tuner for Age and Gender Prediction"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "78a9f4f1",
   "metadata": {},
   "source": [
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "https://keras.io/keras_tuner/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5e821f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfd9530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0cc3050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import keras_tuner\n",
    "from keras_tuner.tuners import RandomSearch, Hyperband, BayesianOptimization\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from IPython.display import Image\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca55054",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27b046d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGE: x_train: (14396, 64, 64, 1), y_train_age: (14396,)\n",
      "     x_val:    (3600, 64, 64, 1), y_val_age:    (3600,)\n",
      "     x_test:   (4499, 64, 64, 1), y_test_age:   (4499,)\n",
      "\n",
      "GENDER: x_train: (14396, 64, 64, 1), y_train_gen: (14396,)\n",
      "        x_val:   (3600, 64, 64, 1),  y_val_gen:    (3600,)\n",
      "        x_test:  (4499, 64, 64, 1),  y_test_gen:   (4499,)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load('train_val_test/x_train.npy')\n",
    "x_val = np.load('train_val_test/x_val.npy')\n",
    "x_test = np.load('train_val_test/x_test.npy')\n",
    "\n",
    "y_train_age = np.load('train_val_test/y_train_age.npy')\n",
    "y_val_age = np.load('train_val_test/y_val_age.npy')\n",
    "y_test_age = np.load('train_val_test/y_test_age.npy')\n",
    "\n",
    "y_train_gen = np.load('train_val_test/y_train_gen.npy')\n",
    "y_val_gen = np.load('train_val_test/y_val_gen.npy')\n",
    "y_test_gen = np.load('train_val_test/y_test_gen.npy')\n",
    "\n",
    "print(f'AGE: x_train: {x_train.shape}, y_train_age: {y_train_age.shape}\\n\\\n",
    "     x_val:    {x_val.shape}, y_val_age:    {y_val_age.shape}\\n\\\n",
    "     x_test:   {x_test.shape}, y_test_age:   {y_test_age.shape}')\n",
    "print('')\n",
    "print(f'GENDER: x_train: {x_train.shape}, y_train_gen: {y_train_gen.shape}\\n\\\n",
    "        x_val:   {x_val.shape},  y_val_gen:    {y_val_gen.shape}\\n\\\n",
    "        x_test:  {x_test.shape},  y_test_gen:   {y_test_gen.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13910790",
   "metadata": {},
   "source": [
    "## Keras model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a5ba539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# размер входящего изображения\n",
    "x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f544475b",
   "metadata": {},
   "source": [
    "### age model for keras tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2676af33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_model_tuner(hp):                                # random search passes this hyperparameter() object \n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add(Input(shape=x_train.shape[1:]))\n",
    "\n",
    "    model.add(Conv2D(hp.Int('n_filters_1',\n",
    "                                min_value=16,\n",
    "                                max_value=128,\n",
    "                                step=16), (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(hp.Int('n_filters_2',\n",
    "                                min_value=128,\n",
    "                                max_value=256,\n",
    "                                step=16), (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(hp.Int('n_filters_3',\n",
    "                                min_value=256,\n",
    "                                max_value=448,\n",
    "                                step=32), (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(hp.Int('n_filters_4',\n",
    "                                min_value=448,\n",
    "                                max_value=526,\n",
    "                                step=32), (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(hp.Int('n_units_1',        \n",
    "                                   min_value=128,   \n",
    "                                   max_value=512,   \n",
    "                                   step=32),\n",
    "                     activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(1,activation='relu',name='age_out'))\n",
    "    \n",
    "    \n",
    "    model.compile(tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss='mse',\n",
    "                  metrics=['mae'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b91909",
   "metadata": {},
   "source": [
    "### AGE ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bda2bda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 64\n",
    "\n",
    "datagen_age = ImageDataGenerator(rescale=1./255., \n",
    "                                 rotation_range = 20,\n",
    "                                 width_shift_range = 0.1,\n",
    "                                 height_shift_range = 0.1,\n",
    "                                 shear_range = 0.1,\n",
    "                                 zoom_range = 0.2,\n",
    "                                 horizontal_flip = True,\n",
    "                                 fill_mode = 'nearest')\n",
    "\n",
    "train_age = datagen_age.flow(x_train, y_train_age, batch_size=batch_size)\n",
    "\n",
    "val_datagen_age = ImageDataGenerator(rescale=1./255., \n",
    "                                     rotation_range = 20,\n",
    "                                     width_shift_range = 0.1,\n",
    "                                     height_shift_range = 0.1,\n",
    "                                     shear_range = 0.1,\n",
    "                                     zoom_range = 0.2,\n",
    "                                     horizontal_flip = True,\n",
    "                                     fill_mode = 'nearest')\n",
    "\n",
    "val_age = val_datagen_age.flow(x_val, y_val_age, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c5861b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1c4e9e11540>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_model_tuner(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fda6c72",
   "metadata": {},
   "source": [
    "### Создаем tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bdcbb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    age_model_tuner,             # функция создания модели\n",
    "    objective='val_mae',         # метрика, которую нужно оптимизировать - \n",
    "    max_trials=30,               # максимальное количество запусков обучения \n",
    "    directory='test_age_model',  # каталог, куда сохраняются обученные сети  \n",
    "    project_name='age')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2d9c32",
   "metadata": {},
   "source": [
    "### Запускаем подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b3a0de",
   "metadata": {},
   "source": [
    "#### Пространство поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "82574f3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 5\n",
      "n_filters_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 128, 'step': 16, 'sampling': None}\n",
      "n_filters_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 128, 'max_value': 256, 'step': 16, 'sampling': None}\n",
      "n_filters_3 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 256, 'max_value': 448, 'step': 32, 'sampling': None}\n",
      "n_filters_4 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 448, 'max_value': 526, 'step': 32, 'sampling': None}\n",
      "n_units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 128, 'max_value': 512, 'step': 32, 'sampling': None}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff9ed69",
   "metadata": {},
   "source": [
    "#### Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "73a76a3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 11m 12s]\n",
      "val_mae: 12.191315650939941\n",
      "\n",
      "Best val_mae So Far: 11.008752822875977\n",
      "Total elapsed time: 04h 54m 21s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_age,                # train\n",
    "             batch_size=64,            # Размер мини-выборки\n",
    "             epochs=30,                # Количество эпох обучения \n",
    "             validation_data=val_age,  # Часть данных, которая будет использоваться для проверки\n",
    "             verbose=1\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1210a121",
   "metadata": {},
   "source": [
    "#### Выбираем лучшую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5d4b4ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in test_age_model\\age\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x00000221432EB460>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_filters_1: 96\n",
      "n_filters_2: 176\n",
      "n_filters_3: 416\n",
      "n_filters_4: 512\n",
      "n_units_1: 256\n",
      "Score: 11.008752822875977\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_filters_1: 48\n",
      "n_filters_2: 144\n",
      "n_filters_3: 416\n",
      "n_filters_4: 512\n",
      "n_units_1: 512\n",
      "Score: 11.085577011108398\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_filters_1: 32\n",
      "n_filters_2: 192\n",
      "n_filters_3: 256\n",
      "n_filters_4: 512\n",
      "n_units_1: 448\n",
      "Score: 11.0856294631958\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_filters_1: 128\n",
      "n_filters_2: 240\n",
      "n_filters_3: 352\n",
      "n_filters_4: 512\n",
      "n_units_1: 448\n",
      "Score: 11.096977233886719\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_filters_1: 128\n",
      "n_filters_2: 240\n",
      "n_filters_3: 320\n",
      "n_filters_4: 512\n",
      "n_units_1: 448\n",
      "Score: 11.172633171081543\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_filters_1: 64\n",
      "n_filters_2: 240\n",
      "n_filters_3: 256\n",
      "n_filters_4: 480\n",
      "n_units_1: 128\n",
      "Score: 11.191986083984375\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_filters_1: 112\n",
      "n_filters_2: 144\n",
      "n_filters_3: 256\n",
      "n_filters_4: 512\n",
      "n_units_1: 224\n",
      "Score: 11.2102689743042\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_filters_1: 112\n",
      "n_filters_2: 176\n",
      "n_filters_3: 384\n",
      "n_filters_4: 480\n",
      "n_units_1: 416\n",
      "Score: 11.223336219787598\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_filters_1: 64\n",
      "n_filters_2: 160\n",
      "n_filters_3: 448\n",
      "n_filters_4: 448\n",
      "n_units_1: 352\n",
      "Score: 11.293208122253418\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_filters_1: 32\n",
      "n_filters_2: 176\n",
      "n_filters_3: 352\n",
      "n_filters_4: 480\n",
      "n_units_1: 320\n",
      "Score: 11.327075004577637\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359dac54",
   "metadata": {},
   "source": [
    "#### Получаем три лучших модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d6f8115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2931d7",
   "metadata": {},
   "source": [
    "#### Оцениваем качество модели на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8f71c618",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 96)        960       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 62, 62, 96)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 96)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 176)       152240    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 29, 29, 176)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 176)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 416)       659360    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 12, 12, 416)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 416)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 512)         1917440   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 2, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 2048)             8192      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " age_out (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,262,993\n",
      "Trainable params: 3,258,897\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n",
      "22/22 [==============================] - 3s 105ms/step - loss: 27656128.0000 - mae: 5097.0020\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 48)        480       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 62, 62, 48)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 48)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 144)       62352     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 29, 29, 144)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 144)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 416)       539552    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 12, 12, 416)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 416)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 512)         1917440   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 2, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 2048)             8192      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " age_out (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,577,617\n",
      "Trainable params: 3,573,521\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n",
      "22/22 [==============================] - 1s 57ms/step - loss: 20037102.0000 - mae: 4013.5950\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        320       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 62, 62, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 192)       55488     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 29, 29, 192)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 192)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 256)       442624    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 12, 12, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 2, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 2048)             8192      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 448)               917952    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 448)               0         \n",
      "                                                                 \n",
      " age_out (Dense)             (None, 1)                 449       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,605,185\n",
      "Trainable params: 2,601,089\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 44ms/step - loss: 19524792.0000 - mae: 4241.1655\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "  model.summary()\n",
    "  model.evaluate(x_test, y_test)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf81e77e",
   "metadata": {},
   "source": [
    "Выбрана модель:\n",
    "\n",
    "Hyperparameters:\n",
    "\n",
    "n_filters_1: 96\n",
    "\n",
    "n_filters_2: 176\n",
    "\n",
    "n_filters_3: 416\n",
    "\n",
    "n_filters_4: 512\n",
    "\n",
    "n_units_1: 256\n",
    "\n",
    "Score: 11.008752822875977"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29834e7f",
   "metadata": {},
   "source": [
    "### gen model for keras tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f10b3762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model_tuner(hp):\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.Input(x_train.shape[1:]))\n",
    "\n",
    "    model.add(Conv2D(hp.Int('filter_11',\n",
    "                                min_value=16,\n",
    "                                max_value=128,\n",
    "                                step=16), (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(hp.Int('filter_12',\n",
    "                                min_value=128,\n",
    "                                max_value=256,\n",
    "                                step=16), (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(hp.Int('filter_13',\n",
    "                                min_value=256,\n",
    "                                max_value=512,\n",
    "                                step=32), (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(hp.Int('units_11',        \n",
    "                                   min_value=128,   \n",
    "                                   max_value=512,   \n",
    "                                   step=32),\n",
    "                     activation='relu'))\n",
    "    model.add(Dropout(0.6))\n",
    "    \n",
    "    model.add(Dense(2,activation='softmax',name='gen_out'))\n",
    "    \n",
    "#     model = tf.keras.models.Model(inputs=inputs, outputs=outputs_age)\n",
    "    \n",
    "    model.compile(tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "24a36a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x22125852ee0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model_tuner(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9898614",
   "metadata": {},
   "source": [
    "### GENDER ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e7b854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 64\n",
    "\n",
    "y_train_gen = tf.keras.utils.to_categorical(y_train[:,1], num_classes=2)\n",
    "y_val_gen = tf.keras.utils.to_categorical(y_val[:,1], num_classes=2)\n",
    "\n",
    "datagen_gen = ImageDataGenerator(rescale=1./255., \n",
    "                                 rotation_range = 20,\n",
    "                                 width_shift_range = 0.1,\n",
    "                                 height_shift_range = 0.1,\n",
    "                                 shear_range = 0.1,\n",
    "                                 zoom_range = 0.2,\n",
    "                                 horizontal_flip = True,\n",
    "                                 fill_mode = 'nearest') \n",
    "\n",
    "train_gender = datagen_gen.flow(x_train, y_train_gen, batch_size=batch_size)\n",
    "\n",
    "val_datagen_gender = ImageDataGenerator(rescale=1./255., \n",
    "                                        rotation_range = 20,\n",
    "                                        width_shift_range = 0.1,\n",
    "                                        height_shift_range = 0.1,\n",
    "                                        shear_range = 0.1,\n",
    "                                        zoom_range = 0.2,\n",
    "                                        horizontal_flip = True,\n",
    "                                        fill_mode = 'nearest')\n",
    "\n",
    "val_gender = val_datagen_gender.flow(x_val, y_val_gen, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd346ee",
   "metadata": {},
   "source": [
    "### Создаем tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8b569b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    gen_model_tuner,                   # функция создания модели\n",
    "    objective='val_accuracy',         # метрика, которую нужно оптимизировать - \n",
    "    max_trials=10,               # максимальное количество запусков обучения \n",
    "    directory='test_gen_model',  # каталог, куда сохраняются обученные сети  \n",
    "    project_name='gen'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662288e",
   "metadata": {},
   "source": [
    "### Запускаем подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c39e38",
   "metadata": {},
   "source": [
    "#### Пространство поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52996705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "filter_11 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 128, 'step': 16, 'sampling': None}\n",
      "filter_12 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 128, 'max_value': 256, 'step': 16, 'sampling': None}\n",
      "filter_13 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 256, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_11 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 128, 'max_value': 512, 'step': 32, 'sampling': None}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1de7e4e",
   "metadata": {},
   "source": [
    "#### Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7ba12e19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 04m 22s]\n",
      "val_accuracy: 0.7839285731315613\n",
      "\n",
      "Best val_accuracy So Far: 0.8089285492897034\n",
      "Total elapsed time: 00h 38m 26s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_gender,                # train\n",
    "             batch_size=64,            # Размер мини-выборки\n",
    "             epochs=10,                # Количество эпох обучения \n",
    "             validation_data=val_gender,  # Часть данных, которая будет использоваться для проверки\n",
    "             verbose=1\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5f82f0",
   "metadata": {},
   "source": [
    "#### Выбираем лучшую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ea46ca06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in test_gen_model\\gen\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x000002213D19A3A0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "filter_11: 48\n",
      "filter_12: 240\n",
      "filter_13: 480\n",
      "units_11: 416\n",
      "Score: 0.8089285492897034\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "filter_11: 64\n",
      "filter_12: 128\n",
      "filter_13: 288\n",
      "units_11: 416\n",
      "Score: 0.7892857193946838\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "filter_11: 112\n",
      "filter_12: 144\n",
      "filter_13: 480\n",
      "units_11: 384\n",
      "Score: 0.7857142686843872\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "filter_11: 80\n",
      "filter_12: 176\n",
      "filter_13: 320\n",
      "units_11: 256\n",
      "Score: 0.7839285731315613\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "filter_11: 16\n",
      "filter_12: 208\n",
      "filter_13: 416\n",
      "units_11: 224\n",
      "Score: 0.7767857313156128\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "filter_11: 96\n",
      "filter_12: 208\n",
      "filter_13: 512\n",
      "units_11: 448\n",
      "Score: 0.7749999761581421\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "filter_11: 48\n",
      "filter_12: 160\n",
      "filter_13: 448\n",
      "units_11: 224\n",
      "Score: 0.7732142806053162\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "filter_11: 32\n",
      "filter_12: 176\n",
      "filter_13: 352\n",
      "units_11: 256\n",
      "Score: 0.7714285850524902\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "filter_11: 16\n",
      "filter_12: 144\n",
      "filter_13: 256\n",
      "units_11: 384\n",
      "Score: 0.7678571343421936\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "filter_11: 16\n",
      "filter_12: 240\n",
      "filter_13: 352\n",
      "units_11: 384\n",
      "Score: 0.762499988079071\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c99637",
   "metadata": {},
   "source": [
    "#### Получаем три лучших модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ba9490d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f225933",
   "metadata": {},
   "source": [
    "#### Оцениваем качество модели на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c2365a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 48)        480       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 62, 62, 48)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 48)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 240)       103920    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 29, 29, 240)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 240)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 480)       1037280   \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 12, 12, 480)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 480)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 17280)             0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 17280)            69120     \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 416)               7188896   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 416)               0         \n",
      "                                                                 \n",
      " gen_out (Dense)             (None, 2)                 834       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,400,530\n",
      "Trainable params: 8,365,970\n",
      "Non-trainable params: 34,560\n",
      "_________________________________________________________________\n",
      "22/22 [==============================] - 3s 98ms/step - loss: -1969.9236 - accuracy: 0.9829\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 64)        640       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 62, 62, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 128)       73856     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 29, 29, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 288)       332064    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 12, 12, 288)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 288)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 10368)             0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 10368)            41472     \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 416)               4313504   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 416)               0         \n",
      "                                                                 \n",
      " gen_out (Dense)             (None, 2)                 834       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,762,370\n",
      "Trainable params: 4,741,634\n",
      "Non-trainable params: 20,736\n",
      "_________________________________________________________________\n",
      "22/22 [==============================] - 1s 48ms/step - loss: -1033.2708 - accuracy: 0.9286\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 112)       1120      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 62, 62, 112)       0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 112)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 144)       145296    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 29, 29, 144)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 144)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 480)       622560    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 12, 12, 480)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 480)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 17280)             0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 17280)            69120     \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 384)               6635904   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 384)               0         \n",
      "                                                                 \n",
      " gen_out (Dense)             (None, 2)                 770       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,474,770\n",
      "Trainable params: 7,440,210\n",
      "Non-trainable params: 34,560\n",
      "_________________________________________________________________\n",
      "22/22 [==============================] - 2s 87ms/step - loss: -1451.9955 - accuracy: 0.8814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "  model.summary()\n",
    "  model.evaluate(x_test, y_test)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b4dbb4",
   "metadata": {},
   "source": [
    "Выбрана модель:\n",
    "\n",
    "Hyperparameters:\n",
    "\n",
    "filter_11: 48\n",
    "\n",
    "filter_12: 240\n",
    "\n",
    "filter_13: 480\n",
    "\n",
    "units_11: 416\n",
    "\n",
    "Score: 0.8089285492897034"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e71a43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "286.825px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
